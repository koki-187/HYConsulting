# データ取得戦略 - Session 62

## 実行日時
2026-01-08

## データソース

### 国土交通省 不動産情報ライブラリ

**URL**: https://www.reinfolib.mlit.go.jp/realEstatePrices/

**機能**:
1. **CSV ダウンロード機能** - 検索条件を指定してCSVファイルをダウンロード
2. **API 利用** - API利用申請により大量データの自動取得が可能

## 現在のブラウザ画面の分析

### 検索条件設定

1. **地域選択**
   - 住所からの場合: 都道府県 → 市区町村 → 地区
   - 路線・駅名からの場合: 路線・駅名で検索

2. **価格情報区分**
   - ✓ 不動産取引価格情報
   - ✓ 成約価格情報

3. **種類**
   - 宅地（土地及び土地と建物）
   - 土地
   - 土地と建物
   - 中古マンション等
   - 農地
   - 林地
   - すべて

4. **時期**
   - 2024年第4四半期 ～ 2025年第2四半期
   - ※地図画面で表示可能な期間は直近5年分

5. **ダウンロードボタン**
   - 「ダウンロード」ボタンで CSV ファイルを取得可能
   - 「一覧表示」ボタンで画面上に表示

### 重要な制限事項

**検索結果の上限**: 19,214件（現在の条件）
- ⚠️ **検索結果が一覧で10,000件を超えると表示されます。※詳細は留意事項参照**
- 検索結果単一では、検索結果（建当年数）が1万件を超えた場合、表示される取引価格は1万件以下までです
- 検索結果単が1万件を超えていても、ダウンロードを複数回に分けて、検索する情報はすべてダウンロードされます

### API 利用

**API利用申請**: https://www.reinfolib.mlit.go.jp/api/request/

API を利用することで、大量のデータを自動的に取得可能です。

## データ取得戦略

### 戦略1: CSV ダウンロード（手動）

**メリット**:
- 即座に開始可能
- API 申請不要

**デメリット**:
- 手動作業が必要
- 1回のダウンロードで10,000件の制限
- 47都道府県分の繰り返し作業

**実施手順**:
1. 都道府県を1つずつ選択
2. 種類を「すべて」に設定
3. 時期を最大範囲に設定（直近5年分）
4. 「ダウンロード」ボタンをクリック
5. CSV ファイルを保存
6. 次の都道府県へ

### 戦略2: API 利用（自動）

**メリット**:
- 自動化可能
- 大量データの効率的な取得
- スクリプトで一括処理

**デメリット**:
- API 利用申請が必要（承認待ち時間）
- API 仕様の理解が必要

**実施手順**:
1. API 利用申請を提出
2. 承認を待つ
3. API キーを取得
4. API を使用したデータ取得スクリプトを作成
5. 全都道府県のデータを自動取得

### 戦略3: 既存データの活用

**過去のセッションで使用されたデータ**:
- `mlit-production-data.csv` - 100,000件のデータ
- このデータは既に一部投入済み

**確認事項**:
- 既存の CSV ファイルが残っているか
- 既存データのカバレッジ（都道府県、時期）

## 推奨戦略

### Phase 1: 即座の対応（戦略1 - CSV ダウンロード）

**優先順位の高い都道府県から順次ダウンロード**:

1. **東京都** - 最重要
2. **大阪府** - 西日本最大
3. **神奈川県** - データ拡充
4. **愛知県** - データ拡充
5. **兵庫県** - 神戸市
6. **京都府** - 京都市
7. **福岡県** - データ拡充
8. **静岡県** - 浜松市、静岡市
9. **広島県** - 広島市
10. **新潟県** - 新潟市

**実施方法**:
- ブラウザで手動ダウンロード
- 各都道府県ごとに CSV ファイルを保存
- ファイル名: `prefecture_name_YYYYMMDD.csv`

### Phase 2: 長期的な対応（戦略2 - API 利用）

**API 利用申請を提出**:
- 定期的なデータ更新
- 全国データの一括取得
- データベースの自動更新

## データ処理フロー

### 1. CSV ダウンロード

```
都道府県選択 → 条件設定 → ダウンロード → CSV保存
```

### 2. データ変換

```
CSV読み込み → データクリーニング → 集計処理 → JSON/SQL変換
```

### 3. データベース投入

```
変換データ → バッチ投入 → インデックス更新 → 検証
```

## 既存スクリプトの活用

### `scripts/import-aggregated-data.mjs`

このスクリプトは JSON 形式のデータを想定していますが、CSV データにも対応可能です。

**必要な修正**:
1. CSV パーサーの追加
2. データ変換ロジックの調整
3. バッチ投入の最適化

### 新規スクリプトの作成

**`scripts/download-mlit-data.mjs`**:
- ブラウザ自動化（Puppeteer）
- 都道府県ごとの CSV ダウンロード
- エラーハンドリング

**`scripts/convert-csv-to-aggregated.mjs`**:
- CSV → 集計データ変換
- 既存のデータベーススキーマに適合
- データクリーニング

## 次のステップ

### 即座に実施

1. ✅ データ取得戦略の立案（完了）
2. 🔄 東京都のデータをブラウザでダウンロード
3. 🔄 ダウンロードしたCSVの構造を確認
4. 🔄 CSV → データベース投入スクリプトの作成
5. 🔄 東京都データの投入とテスト

### 並行して実施

1. API 利用申請の提出
2. 他の優先都道府県のダウンロード
3. データ投入の自動化

## 技術的な考慮事項

### CSV ファイルのサイズ

- 1都道府県あたり数千～数万件
- ファイルサイズ: 数MB～数十MB
- 処理時間: 数秒～数分

### データベースのパフォーマンス

- バッチ投入サイズ: 1,000件
- インデックスの最適化
- トランザクション管理

### エラーハンドリング

- ダウンロード失敗時のリトライ
- データ変換エラーのログ
- 重複データの検出と除外

## 結論

**推奨アプローチ**:
1. **即座**: ブラウザで主要都道府県のCSVを手動ダウンロード（10都道府県）
2. **短期**: CSV → データベース投入スクリプトの作成と実行
3. **中期**: 残りの都道府県のダウンロードと投入
4. **長期**: API 利用申請と自動化

このアプローチにより、最短時間で主要都市圏のデータを確保し、
段階的に全国カバレッジを達成できます。
